{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3acb7970-2557-488e-a275-4c4b9afc32bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install pystac rasterio stac-geoparquet shapely pyarrow==17.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0ad007-a15e-450d-9ac0-b6a7deae9e60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyarrow\n",
    "print(pyarrow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c30e6b24-f84f-4173-8cfc-8d9329def60a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b3bc9ac-e4c8-464a-b08f-8eadc48c5e86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pystac\n",
    "import rasterio\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import stac_geoparquet.arrow as sg_arrow\n",
    "\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Polygon, mapping\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from pystac.extensions.eo import Band, EOExtension\n",
    "from pystac.extensions.projection import ProjectionExtension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff91b31e-9719-4730-8999-9ee745bb5ef1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eods_dirs = [\n",
    "    '/mnt/eods/sentinel2/ARCSI/2024/01/',\n",
    "    '/mnt/eods/sentinel2/ARCSI/2024/02/',\n",
    "    '/mnt/eods/sentinel2/ARCSI/2024/03/',\n",
    "    '/mnt/eods/sentinel2/ARCSI/2024/04/',\n",
    "    '/mnt/eods/sentinel2/ARCSI/2024/05/',\n",
    "    '/mnt/eods/sentinel2/ARCSI/2024/06/'\n",
    "    ]\n",
    "\n",
    "def list_files_recursively(directories, extension):\n",
    "    files = []\n",
    "    for directory in directories:\n",
    "        dirs_to_process = [directory]\n",
    "        while dirs_to_process:\n",
    "            current_dir = dirs_to_process.pop(0)\n",
    "            for file_info in dbutils.fs.ls(current_dir):\n",
    "                if file_info.isDir():\n",
    "                    dirs_to_process.append(file_info.path)\n",
    "                elif file_info.name.endswith(extension):\n",
    "                    files.append(file_info.path)\n",
    "    return files\n",
    "\n",
    "# List all 10-band surface reflectance Geotiffs\n",
    "image_files = list_files_recursively(eods_dirs, '_vmsk_sharp_rad_srefdem_stdsref.tif')\n",
    "print(f\"Found {len(image_files)} 10-band geotiff(s)\")\n",
    "\n",
    "# Convert the paths from 'dbfs:/' to '/dbfs/' to allow the `enable_file_access` 'path warming' function to work\n",
    "image_paths = [file.replace('dbfs:/', '/dbfs/') for file in image_files]\n",
    "\n",
    "for path in image_paths[:5]:\n",
    "    print(path)\n",
    "\n",
    "# List all metadata .xml files\n",
    "metadata_files = list_files_recursively(eods_dirs, '_meta.xml')\n",
    "print(f\"Found {len(metadata_files)} metadata file(s)\")\n",
    "\n",
    "metadata_paths = [file.replace('dbfs:/', '/dbfs/') for file in metadata_files]\n",
    "\n",
    "for path in metadata_paths[:5]:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7ee18ce-8a85-4076-a4be-da3b84f3d0e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sentinel2_eods_bands = [\n",
    "    Band.create(name='B02', common_name='blue', description='Band 2 - Blue', center_wavelength='0.49', full_width_half_max='0.098'),\n",
    "    Band.create(name='B03', common_name='green', description='Band 3 - Green', center_wavelength='0.56', full_width_half_max='0.045'),\n",
    "    Band.create(name='B04', common_name='red', description='Band 4 - Red', center_wavelength='0.665', full_width_half_max='0.038'),\n",
    "    Band.create(name='B05', common_name='rededge071', description='Band 5 - Vegetation red edge 1', center_wavelength='0.704', full_width_half_max='0.019'),\n",
    "    Band.create(name='B06', common_name='rededge075', description='Band 6 - Vegetation red edge 2', center_wavelength='0.74', full_width_half_max='0.018'),\n",
    "    Band.create(name='B07', common_name='rededge078', description='Band 7 - Vegetation red edge 3', center_wavelength='0.783', full_width_half_max='0.028'),\n",
    "    Band.create(name='B08', common_name='nir', description='Band 8 - NIR', center_wavelength='0.842', full_width_half_max='0.145'),\n",
    "    Band.create(name='B8A', common_name='nir08', description='Band 8A - Vegetation red edge 4', center_wavelength='0.865', full_width_half_max='0.033'),\n",
    "    Band.create(name='B11', common_name='swir16', description='Band 11 - SWIR (1.6)', center_wavelength='1.61', full_width_half_max='0.143'),\n",
    "    Band.create(name='B12', common_name='swir22', description='Band 12 - SWIR (2.2)', center_wavelength='2.19', full_width_half_max='0.242')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22d86d5f-4980-4f9c-8616-847f5334ee20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = pystac.Catalog(id='Earth Observation Data Service', description='This catalog is a proof of concept using Sentinel-2 scenes from EODS.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15814ce3-a175-4a3e-bbc6-04aa8cc1e427",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def enable_file_access(pth):\n",
    "    \"\"\"\n",
    "    For a given file path, iterate over the parent directories and attempt to list them using `!ls {str(p)} > /dev/null`, which seems to cache the path within the Databricks environment, allowing IO operations on it.\n",
    "    \"\"\"\n",
    "    item = Path(pth)\n",
    "\n",
    "    # Get the parent directories of the path excluding the first 4 (e.g., '/dbfs/', 'mnt', 'eods', 'sentinel1' or 'sentinel2')\n",
    "    parent_pths = list(reversed(item.parents))[4:]\n",
    "\n",
    "    # Iterate through the parent directories and list their contents\n",
    "    for p in parent_pths:\n",
    "        #dbutils.fs.ls(str(p).replace('/dbfs/', ''))\n",
    "        !ls {str(p)} > /dev/null\n",
    "\n",
    "# Ensure the file paths are accessible\n",
    "for img_path in image_paths:\n",
    "    enable_file_access(img_path)\n",
    "\n",
    "for metadata_path in metadata_paths:\n",
    "    enable_file_access(metadata_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8c28d7b-8d01-46ad-84c3-45df101b3986",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following main workflow functions to create STAC items from .tif files in the EODS mount \n",
    "have been developed based on this tutorial: https://stacspec.org/en/tutorials/3-create-stac-item-with-extension/\n",
    "\"\"\"\n",
    "\n",
    "def get_bbox_and_footprint(raster):\n",
    "    with rasterio.open(raster) as r:\n",
    "        bounds = r.bounds\n",
    "        bbox = [bounds.left, bounds.bottom, bounds.right, bounds.top]\n",
    "        footprint = Polygon([\n",
    "            [bounds.left, bounds.bottom],\n",
    "            [bounds.left, bounds.top],\n",
    "            [bounds.right, bounds.top],\n",
    "            [bounds.right, bounds.bottom]\n",
    "        ])\n",
    "    return (bbox, mapping(footprint))\n",
    "\n",
    "# Function to create a basic STAC item from a raster image\n",
    "def create_basic_item(img_path):\n",
    "    bbox, footprint = get_bbox_and_footprint(img_path)\n",
    "    item_id = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    datetime_utc = datetime.fromtimestamp(os.path.getmtime(img_path), tz=timezone.utc)\n",
    "    \n",
    "    item = pystac.Item(\n",
    "        id=item_id,\n",
    "        geometry=footprint,\n",
    "        bbox=bbox,\n",
    "        datetime=datetime_utc,\n",
    "        properties={}\n",
    "    )\n",
    "    \n",
    "    asset = pystac.Asset(href=img_path, media_type=pystac.MediaType.GEOTIFF)\n",
    "    item.add_asset(\"image\", asset)\n",
    "    \n",
    "    return item\n",
    "\n",
    "def apply_eo_extension(item, asset, metadata_path):\n",
    "    eo = EOExtension.ext(item, add_if_missing=True)\n",
    "    eo.apply(bands=sentinel2_eods_bands)\n",
    "    \n",
    "    eo_on_asset = EOExtension.ext(asset)\n",
    "    eo_on_asset.apply(sentinel2_eods_bands)\n",
    "    \n",
    "    tree = ET.parse(metadata_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    supplemental_info = root.find(\".//gmd:supplementalInformation/gco:CharacterString\", \n",
    "                                  namespaces={'gmd': 'http://www.isotc211.org/2005/gmd',\n",
    "                                              'gco': 'http://www.isotc211.org/2005/gco'})\n",
    "    \n",
    "    if supplemental_info is not None and supplemental_info.text:\n",
    "        match = re.search(r'ARCSI_CLOUD_COVER:\\s*([\\d.]+)', supplemental_info.text)\n",
    "        if match:\n",
    "            eo.cloud_cover = float(match.group(1))\n",
    "\n",
    "def apply_projection_extension(item):\n",
    "    proj_ext = ProjectionExtension.ext(item, add_if_missing=True)\n",
    "    proj_ext.epsg = 27700\n",
    "\n",
    "def add_common_metadata(item):\n",
    "    item.common_metadata.platform = \"Sentinel-2\"\n",
    "    item.common_metadata.instruments = \"msi\"\n",
    "    item.common_metadata.gsd = 10\n",
    "\n",
    "# Process an individual image and update catalog\n",
    "def process_image(img_path, catalog):\n",
    "    item = create_basic_item(img_path)\n",
    "    asset = item.assets[\"image\"]\n",
    "    metadata_path = img_path.replace('.tif', '_meta.xml')\n",
    "    \n",
    "    apply_eo_extension(item, asset, metadata_path)\n",
    "    apply_projection_extension(item)\n",
    "    add_common_metadata(item)\n",
    "    \n",
    "    catalog.add_item(item)\n",
    "\n",
    "# Main function to process all images\n",
    "def process_all_images(image_paths, catalog):\n",
    "    for img_path in image_paths:\n",
    "        process_image(img_path, catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "144a08c7-adb9-4443-9fc5-3b93a28e2ce0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "process_all_images(image_paths, catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b23bb21b-d933-43d1-b457-12abdc07a541",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# FileStore location for the test STAC\n",
    "output_dir = '/FileStore/tomkdefra/test_stac'\n",
    "output_dir_dbfs = '/dbfs/FileStore/tomkdefra/test_stac'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "dbutils.fs.mkdirs(output_dir)\n",
    "\n",
    "# Normalise HREFs\n",
    "catalog.normalize_hrefs('/dbfs' + (output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "016beeaf-1fb2-4a53-9541-6e69a8d11a57",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the catalog\n",
    "catalog.save(catalog_type=pystac.CatalogType.SELF_CONTAINED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa76577d-5e33-4ef3-beee-88cf8c1f3a97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_file = os.path.join(output_dir_dbfs, 'catalog.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "784167a7-4cd7-41e9-aea9-234151012603",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "read_catalog = pystac.Catalog.from_file(catalog_file)\n",
    "catalog_json = read_catalog.to_dict()\n",
    "print(json.dumps(catalog_json, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "623ba9fd-273f-4c18-94fb-c023d8af3a73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Access and print the JSON for first n items\n",
    "items = list(read_catalog.get_items())\n",
    "n_items_json = [item.to_dict() for item in items[:1]]\n",
    "print(\"\\nn items in the catalog:\")\n",
    "print(json.dumps(n_items_json, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd6bb235-d62a-4eb0-9f62-ce0248bb7eb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def convert_stac_to_geoparquet(catalog, output_file):\n",
    "    \"\"\"\n",
    "    Converts a STAC catalog to a GeoParquet file.\n",
    "\n",
    "    Args:\n",
    "        catalog (pystac.Catalog): The STAC catalog containing items to convert.\n",
    "        output_file (str): The path where the output GeoParquet file will be saved.\n",
    "\n",
    "    The function retrieves all STAC items from the catalog, converts them to an\n",
    "    Apache Arrow format using the stac-geoparquet library, and writes the result\n",
    "    to a GeoParquet file. If an error occurs, it prints the error message and stack trace.\n",
    "\n",
    "    Note:\n",
    "        I think Stac-geoparquet requires a pyarrow version > 16.0.0. The version installed \n",
    "        on the clusters (at least cluster 1c) is 8.0.0 which results in an error. After \n",
    "        pip installing pyarrow==17.0.0 you will need to run dbutils.library.restartPython()\n",
    "        to ensure the cluster is using the up-to-date version.\n",
    "        \n",
    "    Reference: \n",
    "    Based on the example from: https://stac-utils.github.io/stac-geoparquet/latest/examples/naip/#loading-to-arrow\n",
    "    \"\"\"\n",
    "    try:\n",
    "        items = list(catalog.get_all_items())\n",
    "        record_batch_reader = sg_arrow.parse_stac_items_to_arrow(items)\n",
    "        sg_arrow.to_parquet(record_batch_reader, output_file)\n",
    "        print(f\"Successfully created GeoParquet file: {output_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Error type: {type(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "027d1c97-8c6c-4040-bd57-6866705cf9c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_file = \"/dbfs/FileStore/tomkdefra/test_stac_geoparquet.parquet\"\n",
    "convert_stac_to_geoparquet(catalog, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.mv(\"FileStore/tomkdefra/test_stac_geoparquet.parquet\", \"mnt/lab/unrestricted/eods_stac/eods_s2.parquet\", True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3. Create a STAC catalogue that Implements the Extensions Using PySTAC",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
